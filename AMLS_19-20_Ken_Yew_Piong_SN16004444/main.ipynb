{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os, math, import_ipynb, cv2, dlib, warnings, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, plot_confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, learning_curve\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from utils import *\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kenyew/Documents/Git/AMLSassignment19_20/AMLS_19-20_Ken_Yew_Piong_SN16004444'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/Users/kenyew/Documents/Git/AMLSassignment19_20/AMLS_19-20_Ken_Yew_Piong_SN16004444/\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 5000\n",
    "landmark_features_celeba, gender_labels, smiling_labels = extract_features_labels_from_celeba(sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A1 - Gender Recognition from celeba Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n",
      "Best parameters set found on training dataset:\n",
      "\n",
      "{'C': 0.01, 'kernel': 'linear'}\n",
      "\n",
      "Grid scores on training dataset:\n",
      "\n",
      "0.265 (+/-0.002) for {'C': 0.01, 'kernel': 'rbf'}\n",
      "0.265 (+/-0.002) for {'C': 0.05, 'kernel': 'rbf'}\n",
      "0.265 (+/-0.002) for {'C': 0.1, 'kernel': 'rbf'}\n",
      "0.265 (+/-0.002) for {'C': 0.5, 'kernel': 'rbf'}\n",
      "0.466 (+/-0.491) for {'C': 1, 'kernel': 'rbf'}\n",
      "0.820 (+/-0.065) for {'C': 5, 'kernel': 'rbf'}\n",
      "0.842 (+/-0.054) for {'C': 10, 'kernel': 'rbf'}\n",
      "0.909 (+/-0.058) for {'C': 0.01, 'kernel': 'linear'}\n",
      "0.888 (+/-0.089) for {'C': 0.05, 'kernel': 'linear'}\n",
      "0.879 (+/-0.096) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.883 (+/-0.078) for {'C': 0.5, 'kernel': 'linear'}\n",
      "0.883 (+/-0.078) for {'C': 1, 'kernel': 'linear'}\n",
      "0.883 (+/-0.078) for {'C': 5, 'kernel': 'linear'}\n",
      "0.883 (+/-0.078) for {'C': 10, 'kernel': 'linear'}\n",
      "0.710 (+/-0.122) for {'C': 0.01, 'kernel': 'poly'}\n",
      "0.848 (+/-0.064) for {'C': 0.05, 'kernel': 'poly'}\n",
      "0.870 (+/-0.065) for {'C': 0.1, 'kernel': 'poly'}\n",
      "0.885 (+/-0.075) for {'C': 0.5, 'kernel': 'poly'}\n",
      "0.888 (+/-0.088) for {'C': 1, 'kernel': 'poly'}\n",
      "0.898 (+/-0.076) for {'C': 5, 'kernel': 'poly'}\n",
      "0.894 (+/-0.104) for {'C': 10, 'kernel': 'poly'}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full training dataset.\n",
      "The scores are computed on the full testing dataset.\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.91      0.90      2175\n",
      "         1.0       0.91      0.88      0.90      2145\n",
      "\n",
      "    accuracy                           0.90      4320\n",
      "   macro avg       0.90      0.90      0.90      4320\n",
      "weighted avg       0.90      0.90      0.90      4320\n",
      "\n",
      "\n",
      "The confusion matrix is:\n",
      "[[1983  192]\n",
      " [ 247 1898]]\n",
      "\n",
      "Best estimator found: SVC(C=0.01, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='linear',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "Best parameters set found: {'C': 0.01, 'kernel': 'linear'}\n",
      "\n",
      "SVM with GridCV on testing data - Accuracy Score: 0.898 (+/- 0.000)\n",
      "SVM with GridCV on training data - Accuracy Score: 0.936 (+/- 0.000)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Task A1\n",
    "model_A1 = A1(args...)                 # Build model object.\n",
    "acc_A1_train = model_A1.train(args...) # Train model based on the training set (you should fine-tune your model based on validation set.)\n",
    "acc_A1_test = model_A1.test(args...)   # Test model based on the test set.\n",
    "Clean up memory/GPU etc...             # Some code to free memory if necessary.\n",
    "\"\"\"\n",
    "split_percentage = 10\n",
    "feature_type = 'landmarks'\n",
    "cv_folds = 5\n",
    "\n",
    "X_all, X_train, X_test, y_all, y_train, y_test = get_split_data(landmark_features_celeba, gender_labels, split_percentage, feature_type)\n",
    "model_A1, acc_A1_train, acc_A1_test = build_svm_gridcv(X_train, X_test, y_train, y_test, cv_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_A1_plot = plot_learning_curve(model_A1, 'Task A1 Learning Curve - SVM', X_all, y_all, ylim=None, cv=5,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_A1_cm = plot_confusion_matrix(model_A1, X_test, y_test, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_A1_cm = plot_confusion_matrix(model_A1, X_test, y_test, class_names = ['male', 'female'], title = 'Gender Confusion Matrix', figsize = (12,10), cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A2 - Smiling Recognition from celeba Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Task A2\n",
    "model_A2 = A2(args...)\n",
    "acc_A2_train = model_A2.train(args...)\n",
    "acc_A2_test = model_A2.test(args...)\n",
    "Clean up memory/GPU etc...\n",
    "\"\"\"\n",
    "split_percentage = 80\n",
    "feature_type = 'landmarks'\n",
    "cv_folds = 5\n",
    "\n",
    "X_all, X_train, X_test, y_all, y_train, y_test = get_split_data(landmark_features_celeba, smiling_labels, split_percentage, feature_type)\n",
    "model_A2, acc_A2_train, acc_A2_test = build_svm_gridcv(X_train, X_test, y_train, y_test, cv_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_A2_plot = plot_learning_curve(model_A2, 'Task A2 Learning Curve - SVM', X_all, y_all, ylim=None, cv=5,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_A2_cm = plot_confusion_matrix(model_A2, X_test, y_test, class_names = ['no smile', 'smile'], title = 'Smile Confusion Matrix', figsize = (12,10), cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_type = 'rgb'\n",
    "sample_size = 1000\n",
    "img_features_cartoon_set, eye_color_labels, face_shape_labels = extract_features_labels_from_cartoon_set(feature_type, sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B1 - Eye Colour Recognition from cartoon Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Task B1\n",
    "model_B1 = B1(args...)\n",
    "acc_B1_train = model_B1.train(args...)\n",
    "acc_B1_test = model_B1.test(args...)\n",
    "Clean up memory/GPU etc...\n",
    "\"\"\"\n",
    "split_percentage = 80\n",
    "feature_type = 'rgb'\n",
    "cv_folds = 5\n",
    "\n",
    "X_all, X_train, X_test, y_all, y_train, y_test = get_split_data(img_features_cartoon_set, eye_color_labels, split_percentage, feature_type)\n",
    "model_B1, acc_B1_train, acc_B1_test = build_svm_gridcv(X_train, X_test, y_train, y_test, cv_folds)\n",
    "\n",
    "scaled_X_train = scale_data(X_train)\n",
    "scaled_X_test = scale_data(X_test)\n",
    "model_B1_2, acc_B1_2_train, acc_B1_2_test = build_mlp(scaled_X_train, scaled_X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_B1_plot = plot_learning_curve(model_B1, 'Task B1 Learning Curve - SVM', X_train, y_train, ylim=None, cv=5,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_B1_cm = plot_confusion_matrix(model_B1, X_test, y_test, class_names = ['0', '1', '2', '3', '4'], title = 'Eye Colour Matrix', figsize = (12,10), cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B2 - Face Shape Recognition from cartoon Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Task B2\n",
    "model_B2 = B2(args...)\n",
    "acc_B2_train = model_B2.train(args...)\n",
    "acc_B2_test = model_B2.test(args...)\n",
    "Clean up memory/GPU etc...\n",
    "\"\"\"\n",
    "split_percentage = 80\n",
    "feature_type = 'rgb'\n",
    "cv_folds = 5\n",
    "\n",
    "X_all, X_train, X_test, y_all, y_train, y_test = get_split_data(img_features_cartoon_set, face_shape_labels, split_percentage, feature_type)\n",
    "model_B2, acc_B2_train, acc_B2_test = build_svm_gridcv(X_train, X_test, y_train, y_test, cv_folds)\n",
    "\n",
    "scaled_X_train = scale_data(X_train)\n",
    "scaled_X_test = scale_data(X_test)\n",
    "model_B2_2, acc_B2_2_train, acc_B2_2_test = build_mlp(scaled_X_train, scaled_X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_B2_plot = plot_learning_curve(model_B2, 'Task B2 Learning Curve - SVM', X_train, y_train, ylim=None, cv=5,\n",
    "                        n_jobs=None, train_sizes=np.linspace(.1, 1.0, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_B2_cm = plot_confusion_matrix(model_B2, X_test, y_test, class_names = ['0', '1', '2', '3', '4'], title = 'Face Shape Matrix', figsize = (12,10), cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out your results with following format:\n",
    "# print('TA1:{},{};TA2:{},{};TB1:{},{};TB2:{},{};'.format(acc_A1_train, acc_A1_test,\n",
    "#                                                         acc_A2_train, acc_A2_test,\n",
    "#                                                         acc_B1_train, acc_B1_test,\n",
    "#                                                         acc_B2_train, acc_B2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "img_SVM performance: \n",
    "Accuracy: 0.8780092592592592\n",
    "Training Error: 1.0\n",
    "Testing Error: 0.8780092592592592\n",
    "Validation Error: 0.9166666666666664\n",
    "\n",
    "img_SVM_GridCV performance:\n",
    "{'C': 0.1, 'kernel': 'linear'}\n",
    "Accuracy: 0.8900462962962963\n",
    "Training Error: 0.9729166666666667\n",
    "Testing Error: 0.8900462962962963\n",
    "\n",
    "img_SVM with scaled data performance: \n",
    "Accuracy: 0.8891203703703704\n",
    "Training Error: 0.9770833333333333\n",
    "Testing Error: 0.8891203703703704\n",
    "Validation Error: 0.9172916666666666\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SVM with GridCV on TASK A1\n",
    "Best parameters set found on training dataset:\n",
    "\n",
    "{'C': 0.01, 'kernel': 'linear'}\n",
    "\n",
    "Grid scores on training dataset:\n",
    "\n",
    "0.265 (+/-0.004) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.265 (+/-0.004) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.265 (+/-0.004) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.265 (+/-0.004) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.731 (+/-0.178) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.366 (+/-0.406) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.826 (+/-0.073) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.824 (+/-0.092) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.845 (+/-0.102) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.829 (+/-0.090) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.861 (+/-0.071) for {'C': 5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.877 (+/-0.107) for {'C': 5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.855 (+/-0.060) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.878 (+/-0.101) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.909 (+/-0.073) for {'C': 0.01, 'kernel': 'linear'}\n",
    "0.894 (+/-0.056) for {'C': 0.05, 'kernel': 'linear'}\n",
    "0.900 (+/-0.050) for {'C': 0.1, 'kernel': 'linear'}\n",
    "0.885 (+/-0.092) for {'C': 0.5, 'kernel': 'linear'}\n",
    "0.879 (+/-0.091) for {'C': 1, 'kernel': 'linear'}\n",
    "0.879 (+/-0.091) for {'C': 5, 'kernel': 'linear'}\n",
    "0.879 (+/-0.091) for {'C': 10, 'kernel': 'linear'}\n",
    "0.893 (+/-0.097) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.904 (+/-0.083) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.893 (+/-0.097) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.896 (+/-0.098) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.893 (+/-0.097) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.894 (+/-0.096) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.893 (+/-0.097) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.894 (+/-0.096) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.893 (+/-0.097) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.894 (+/-0.096) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.893 (+/-0.097) for {'C': 5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.894 (+/-0.096) for {'C': 5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.893 (+/-0.097) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.894 (+/-0.096) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "\n",
    "Detailed classification report:\n",
    "\n",
    "The model is trained on the full training dataset.\n",
    "The scores are computed on the full testing dataset.\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.89      0.91      0.90      2176\n",
    "         1.0       0.91      0.88      0.90      2144\n",
    "\n",
    "    accuracy                           0.90      4320\n",
    "   macro avg       0.90      0.90      0.90      4320\n",
    "weighted avg       0.90      0.90      0.90      4320\n",
    "\n",
    "\n",
    "Best estimator found: SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)\n",
    "Best parameters set found: {'C': 0.01, 'kernel': 'linear'}\n",
    "SVM with GridCV on testing data - Accuracy Score: 0.898 (+/- 0.000)\n",
    "SVM with GridCV on training data - Accuracy Score: 0.936 (+/- 0.000)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SVM with GridCV on TASK A2\n",
    "# Tuning hyper-parameters for precision\n",
    "\n",
    "Best parameters set found on training dataset:\n",
    "\n",
    "{'C': 5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "\n",
    "Grid scores on training dataset:\n",
    "\n",
    "0.264 (+/-0.005) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.264 (+/-0.005) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.840 (+/-0.093) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.837 (+/-0.123) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.863 (+/-0.055) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.866 (+/-0.088) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.860 (+/-0.062) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.873 (+/-0.076) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.868 (+/-0.066) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.871 (+/-0.060) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.861 (+/-0.095) for {'C': 5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.881 (+/-0.055) for {'C': 5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.850 (+/-0.083) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.881 (+/-0.073) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.878 (+/-0.079) for {'C': 0.01, 'kernel': 'linear'}\n",
    "0.855 (+/-0.081) for {'C': 0.05, 'kernel': 'linear'}\n",
    "0.850 (+/-0.095) for {'C': 0.1, 'kernel': 'linear'}\n",
    "0.842 (+/-0.101) for {'C': 0.5, 'kernel': 'linear'}\n",
    "0.846 (+/-0.119) for {'C': 1, 'kernel': 'linear'}\n",
    "0.833 (+/-0.132) for {'C': 5, 'kernel': 'linear'}\n",
    "0.833 (+/-0.132) for {'C': 10, 'kernel': 'linear'}\n",
    "0.859 (+/-0.085) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.860 (+/-0.074) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.859 (+/-0.085) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.855 (+/-0.101) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.859 (+/-0.085) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.860 (+/-0.085) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.859 (+/-0.085) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.860 (+/-0.085) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.859 (+/-0.085) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.860 (+/-0.085) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.859 (+/-0.085) for {'C': 5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.860 (+/-0.085) for {'C': 5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.859 (+/-0.085) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.860 (+/-0.085) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "\n",
    "Detailed classification report:\n",
    "\n",
    "The model is trained on the full training dataset.\n",
    "The scores are computed on the full testing dataset.\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.86      0.91      0.88      2117\n",
    "         1.0       0.91      0.86      0.88      2203\n",
    "\n",
    "    accuracy                           0.88      4320\n",
    "   macro avg       0.88      0.88      0.88      4320\n",
    "weighted avg       0.88      0.88      0.88      4320\n",
    "\n",
    "\n",
    "Best estimator found: SVC(C=5, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "Best parameters set found: {'C': 5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "SVM with GridCV on testing data - Accuracy Score: 0.881 (+/- 0.000)\n",
    "SVM with GridCV on training data - Accuracy Score: 0.914 (+/- 0.000)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SVM with GridCV on TASK B1\n",
    "# Tuning hyper-parameters for precision\n",
    "\n",
    "Best parameters set found on training dataset:\n",
    "\n",
    "{'C': 0.01, 'kernel': 'linear'}\n",
    "\n",
    "Grid scores on training dataset:\n",
    "\n",
    "0.044 (+/-0.002) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.044 (+/-0.002) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.044 (+/-0.002) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.145 (+/-0.141) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.140 (+/-0.170) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.113 (+/-0.038) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.303 (+/-0.126) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.258 (+/-0.100) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.287 (+/-0.104) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.286 (+/-0.128) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.281 (+/-0.078) for {'C': 5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.318 (+/-0.107) for {'C': 5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.284 (+/-0.098) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.327 (+/-0.102) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.346 (+/-0.043) for {'C': 0.01, 'kernel': 'linear'}\n",
    "0.341 (+/-0.105) for {'C': 0.05, 'kernel': 'linear'}\n",
    "0.340 (+/-0.112) for {'C': 0.1, 'kernel': 'linear'}\n",
    "0.320 (+/-0.114) for {'C': 0.5, 'kernel': 'linear'}\n",
    "0.306 (+/-0.090) for {'C': 1, 'kernel': 'linear'}\n",
    "0.301 (+/-0.102) for {'C': 5, 'kernel': 'linear'}\n",
    "0.306 (+/-0.086) for {'C': 10, 'kernel': 'linear'}\n",
    "0.307 (+/-0.124) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.312 (+/-0.096) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.309 (+/-0.129) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.302 (+/-0.045) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.308 (+/-0.132) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.306 (+/-0.078) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.308 (+/-0.132) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.300 (+/-0.059) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.308 (+/-0.132) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.301 (+/-0.057) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.308 (+/-0.132) for {'C': 5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.300 (+/-0.058) for {'C': 5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.308 (+/-0.132) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.299 (+/-0.056) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "\n",
    "Detailed classification report:\n",
    "\n",
    "The model is trained on the full training dataset.\n",
    "The scores are computed on the full testing dataset.\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.30      0.32      0.31      1408\n",
    "           1       0.25      0.24      0.24      1381\n",
    "           2       0.21      0.14      0.17      1412\n",
    "           3       0.36      0.41      0.38      1395\n",
    "           4       0.52      0.58      0.55      1438\n",
    "\n",
    "    accuracy                           0.34      7034\n",
    "   macro avg       0.33      0.34      0.33      7034\n",
    "weighted avg       0.33      0.34      0.33      7034\n",
    "\n",
    "\n",
    "Best estimator found: SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)\n",
    "Best parameters set found: {'C': 0.01, 'kernel': 'linear'}\n",
    "SVM with GridCV on testing data - Accuracy Score: 0.339 (+/- 0.000)\n",
    "SVM with GridCV on training data - Accuracy Score: 0.559 (+/- 0.000)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SVM with GridCV on TASK B2\n",
    "# Tuning hyper-parameters for precision\n",
    "\n",
    "Best parameters set found on training dataset:\n",
    "\n",
    "{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "\n",
    "Grid scores on training dataset:\n",
    "\n",
    "0.048 (+/-0.001) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.048 (+/-0.001) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.048 (+/-0.001) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.048 (+/-0.001) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.139 (+/-0.166) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.147 (+/-0.070) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.579 (+/-0.191) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.470 (+/-0.212) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.613 (+/-0.080) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.550 (+/-0.129) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.602 (+/-0.104) for {'C': 5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.679 (+/-0.101) for {'C': 5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.606 (+/-0.107) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.688 (+/-0.061) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.674 (+/-0.136) for {'C': 0.01, 'kernel': 'linear'}\n",
    "0.646 (+/-0.123) for {'C': 0.05, 'kernel': 'linear'}\n",
    "0.647 (+/-0.125) for {'C': 0.1, 'kernel': 'linear'}\n",
    "0.598 (+/-0.129) for {'C': 0.5, 'kernel': 'linear'}\n",
    "0.582 (+/-0.126) for {'C': 1, 'kernel': 'linear'}\n",
    "0.554 (+/-0.122) for {'C': 5, 'kernel': 'linear'}\n",
    "0.551 (+/-0.126) for {'C': 10, 'kernel': 'linear'}\n",
    "0.589 (+/-0.120) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.593 (+/-0.110) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.589 (+/-0.120) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.591 (+/-0.111) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.589 (+/-0.120) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.591 (+/-0.111) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.589 (+/-0.120) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.591 (+/-0.111) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.589 (+/-0.120) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.591 (+/-0.111) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.589 (+/-0.120) for {'C': 5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.591 (+/-0.111) for {'C': 5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.589 (+/-0.120) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.591 (+/-0.111) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "\n",
    "Detailed classification report:\n",
    "\n",
    "The model is trained on the full training dataset.\n",
    "The scores are computed on the full testing dataset.\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.68      0.61      0.65      1389\n",
    "           1       0.53      0.65      0.59      1317\n",
    "           2       0.71      0.74      0.72      1497\n",
    "           3       0.67      0.62      0.64      1411\n",
    "           4       0.84      0.77      0.81      1420\n",
    "\n",
    "    accuracy                           0.68      7034\n",
    "   macro avg       0.69      0.68      0.68      7034\n",
    "weighted avg       0.69      0.68      0.68      7034\n",
    "\n",
    "\n",
    "Best estimator found: SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "Best parameters set found: {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "SVM with GridCV on testing data - Accuracy Score: 0.680 (+/- 0.000)\n",
    "SVM with GridCV on training data - Accuracy Score: 0.903 (+/- 0.000)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"./Datasets/celeba/labels.csv\")\n",
    "# df = split_df(df)\n",
    "# print(df)\n",
    "# img_name_data = df['img_name']\n",
    "# gender_data = df['gender']\n",
    "# smiling_data = df['smiling']\n",
    "\n",
    "# model.fit(X_train, y_train).score(X_train, y_train) FOR TRAINING ERROR\n",
    "#     train_errors.append(enet.score(X_train, y_train))\n",
    "#     test_errors.append(enet.score(X_test, y_test))\n",
    "# classification_report(expected, y_1)\n",
    "\n",
    "# Exhaustive List \n",
    "#     param_grid = [\n",
    "#   {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "#   {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "#  ]\n",
    "\n",
    "# def get_data(X, y):\n",
    "#     Y = np.array([y, -(y - 1)]).T\n",
    "#     tr_X = X[:100]\n",
    "#     tr_Y = Y[:100]\n",
    "#     te_X = X[100:]\n",
    "#     te_Y = Y[100:]\n",
    "#     print(len(tr_X))\n",
    "#     print(len(te_X))\n",
    "    \n",
    "#     tr_X = tr_X.reshape(len(tr_X), 68*2)\n",
    "#     tr_Y = list(zip(*tr_Y))[0]\n",
    "#     te_X = te_X.reshape(len(te_X), 68*2)\n",
    "#     te_Y = list(zip(*te_Y))[0]\n",
    "#     return tr_X, tr_Y, te_X, te_Y\n",
    "# tr_X, tr_Y, te_X, te_Y = get_data(landmark_features_celeba, gender_labels)\n",
    "\n",
    "# def scale_data(training_images, test_images):\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(training_images)\n",
    "#     tr_X = scaler.transform(training_images)\n",
    "#     te_X = scaler.transform(test_images)\n",
    "\n",
    "#     return tr_X, te_X\n",
    "\n",
    "# sklearn functions implementation\n",
    "def img_SVM(training_images, training_labels, test_images, test_labels):\n",
    "    classifier = SVC(kernel = \"linear\")\n",
    "    classifier.fit(training_images, training_labels)\n",
    "    pred = classifier.predict(test_images)\n",
    "    print(\"Accuracy:\", accuracy_score(test_labels, pred))\n",
    "#     print(pred)\n",
    "    return pred\n",
    "\n",
    "\n",
    "# pred_img_SVM = img_SVM(tr_X.reshape((100, 68*2)), list(zip(*tr_Y))[0], te_X.reshape((4700, 68*2)), list(zip(*te_Y))[0])\n",
    "# pred_img_MLP = img_MLP(tr_X.reshape((100, 68*2)), list(zip(*tr_Y))[0], te_X.reshape((4700, 68*2)), list(zip(*te_Y))[0])\n",
    "\n",
    "#     print(pd.DataFrame(clf.cv_results_)[['mean_test_score', 'std_test_score', 'params']])\n",
    "#     print(clf.best_score_)\n",
    "#     print(clf.best_params_)\n",
    "#     print(clf.best_estimator_)\n",
    "\n",
    "# CROSS VALIDATION\n",
    "# X_all = landmark_features_celeba.reshape(len(landmark_features_celeba), 68*2)\n",
    "# Y = np.array([gender_labels, -(gender_labels - 1)]).T\n",
    "# y_all = list(zip(*Y))[0]\n",
    "#     acc_score_cv = cross_val_score(clf, X_all, y_all, scoring = 'accuracy', cv=5)\n",
    "#     print('SVM with GridCV on all data with K=5 fold cross validation - Accuracy Score: %.4f (+/- %.2f)' % (acc_score_cv.mean(), acc_score_cv.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # X_all = np.array(landmark_features_cartoon_set).reshape(7815, 68, 2, 1)\n",
    "# X_all = landmark_features_cartoon_set\n",
    "# y_all = eye_color_labels\n",
    "# # print(X_all[0])\n",
    "# print(landmark_features_cartoon_set.shape)\n",
    "# print(X_all[1:].shape)\n",
    "\n",
    "# # Initialising TensorBoard\n",
    "# NAME = f'CNN-binary-classification-64x2-{datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")}'\n",
    "# tensorboard = TensorBoard(log_dir = f'logs/{NAME}')\n",
    "\n",
    "# # Creating the CNN model\n",
    "# model = Sequential() # Initialising the model as a feedforward sequential model layout\n",
    "# \"\"\"\n",
    "# 1st Layer of CNN\n",
    "# \"\"\"\n",
    "# # Conv2D(64, (3,3), input_shape = X.shape[1:]) - 0: number of neurons, 1: window size 2: input shape\n",
    "# model.add(Conv2D(64, (3,3), input_shape = X_all.shape)) # Adding a convolutional layer\n",
    "# model.add(Activation('relu')) # Adding a Rectified Linear Unit activation layer\n",
    "# model.add(MaxPooling2D(pool_size = (2,2))) # Adding a 2x2 pooling layer\n",
    "# \"\"\"\n",
    "# 2nd Layer of CNN\n",
    "# \"\"\"\n",
    "# model.add(Conv2D(64, (3,3))) # Adding a convolutional layer\n",
    "# model.add(Activation('relu')) # Adding an Rectified Linear Unit activation layer\n",
    "# model.add(MaxPooling2D(pool_size = (2,2))) # Adding a 2x2 pooling layer\n",
    "# \"\"\"\n",
    "# 3rd Layer of CNN\n",
    "# \"\"\"\n",
    "# model.add(Flatten()) # flatten data structure from 2-D to 1-D\n",
    "# model.add(Dense(64))\n",
    "# model.add(Activation('relu'))\n",
    "# \"\"\"\n",
    "# Output Layer of CNN\n",
    "# \"\"\"\n",
    "# model.add(Dense(1))\n",
    "# model.add(Activation('sigmoid'))\n",
    "\n",
    "# # Compiling the CNN model\n",
    "# model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "# model.fit(X_all, y_all, batch_size = 32, epochs = 3, validation_split = 0.1, callbacks = [tensorboard]) # passing data in batches of 32 and cross validation split of 10% of data\n",
    "# # with pwd containing logs folger, enter in terminal: tensorboard --logsdir logs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
