{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, import_ipynb, cv2, dlib, warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "\n",
    "from utils import *\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kenyew/Documents/Git/AMLSassignment19_20/AMLS_19-20_Ken_Yew_Piong_SN16004444'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/Users/kenyew/Documents/Git/AMLSassignment19_20/AMLS_19-20_Ken_Yew_Piong_SN16004444/\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmark_features_celeba, gender_labels, smiling_labels = extract_features_labels_from_celeba()\n",
    "# landmark_features_cartoon_set, eye_color_labels, face_shape_labels = extract_features_labels_from_cartoon_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A1 - Gender Recognition from celeba Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Task A1\n",
    "model_A1 = A1(args...)                 # Build model object.\n",
    "acc_A1_train = model_A1.train(args...) # Train model based on the training set (you should fine-tune your model based on validation set.)\n",
    "acc_A1_test = model_A1.test(args...)   # Test model based on the test set.\n",
    "Clean up memory/GPU etc...             # Some code to free memory if necessary.\n",
    "\"\"\"\n",
    "\n",
    "def img_SVM_GridCV(X_train, y_train, X_test, y_test):\n",
    "    # Set the parameters by cross-validation\n",
    "    tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                         'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10]},\n",
    "                        {'kernel': ['linear'], 'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10]},\n",
    "                        {'kernel': ['poly'], 'gamma': [1e-3, 1e-4],\n",
    "                         'C': [0.01, 0.05, 0.1, 0.5, 1, 5, 10]}]\n",
    "\n",
    "    scores = ['precision'] # 'recall'\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "\n",
    "        clf = GridSearchCV(\n",
    "            SVC(), tuned_parameters, cv = 10, scoring='%s_macro' % score\n",
    "        )\n",
    "        clf.fit(X_train, y_train)\n",
    "    \n",
    "        print(\"Best parameters set found on training dataset:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on training dataset:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full training dataset.\")\n",
    "        print(\"The scores are computed on the full testing dataset.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()\n",
    "    \n",
    "    print('Best estimator found:', clf.best_estimator_)\n",
    "    print('Best parameters set found:', clf.best_params_)\n",
    "    acc_score = accuracy_score(y_test, y_pred)\n",
    "    print('SVM with GridCV on testing data - Accuracy Score: %.3f (+/- %.3f)' % (acc_score.mean(), acc_score.std()))\n",
    "    acc_score_train = clf.score(X_train, y_train)\n",
    "    print('SVM with GridCV on training data - Accuracy Score: %.3f (+/- %.3f)' % (acc_score_train.mean(), acc_score_train.std()))\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "\n",
    "X_train, y_train, X_test, y_test = get_split_data(landmark_features_celeba, gender_labels, 80)\n",
    "X_all = landmark_features_celeba.reshape(len(landmark_features_celeba), 68*2)\n",
    "Y = np.array([gender_labels, -(gender_labels - 1)]).T\n",
    "y_all = list(zip(*Y))[0]\n",
    "pred_img_SVM_GridCV = img_SVM_GridCV(X_all, y_all, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A2 - Smiling Recognition from celeba Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Task A2\\nmodel_A2 = A2(args...)\\nacc_A2_train = model_A2.train(args...)\\nacc_A2_test = model_A2.test(args...)\\nClean up memory/GPU etc...\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Task A2\n",
    "model_A2 = A2(args...)\n",
    "acc_A2_train = model_A2.train(args...)\n",
    "acc_A2_test = model_A2.test(args...)\n",
    "Clean up memory/GPU etc...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B1 - Eye Colour Recognition from cartoon Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Task B1\\nmodel_B1 = B1(args...)\\nacc_B1_train = model_B1.train(args...)\\nacc_B1_test = model_B1.test(args...)\\nClean up memory/GPU etc...\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Task B1\n",
    "model_B1 = B1(args...)\n",
    "acc_B1_train = model_B1.train(args...)\n",
    "acc_B1_test = model_B1.test(args...)\n",
    "Clean up memory/GPU etc...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B2 - Face Shape Recognition from cartoon Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Task B2\\nmodel_B2 = B2(args...)\\nacc_B2_train = model_B2.train(args...)\\nacc_B2_test = model_B2.test(args...)\\nClean up memory/GPU etc...\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Task B2\n",
    "model_B2 = B2(args...)\n",
    "acc_B2_train = model_B2.train(args...)\n",
    "acc_B2_test = model_B2.test(args...)\n",
    "Clean up memory/GPU etc...\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n## Print out your results with following format:\\nprint('TA1:{},{};TA2:{},{};TB1:{},{};TB2:{},{};'.format(acc_A1_train, acc_A1_test,\\n                                                        acc_A2_train, acc_A2_test,\\n                                                        acc_B1_train, acc_B1_test,\\n                                                        acc_B2_train, acc_B2_test))\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "## Print out your results with following format:\n",
    "print('TA1:{},{};TA2:{},{};TB1:{},{};TB2:{},{};'.format(acc_A1_train, acc_A1_test,\n",
    "                                                        acc_A2_train, acc_A2_test,\n",
    "                                                        acc_B1_train, acc_B1_test,\n",
    "                                                        acc_B2_train, acc_B2_test))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "img_SVM performance: \n",
    "Accuracy: 0.8780092592592592\n",
    "Training Error: 1.0\n",
    "Testing Error: 0.8780092592592592\n",
    "Validation Error: 0.9166666666666664\n",
    "\n",
    "img_SVM_GridCV performance:\n",
    "{'C': 0.1, 'kernel': 'linear'}\n",
    "Accuracy: 0.8900462962962963\n",
    "Training Error: 0.9729166666666667\n",
    "Testing Error: 0.8900462962962963\n",
    "\n",
    "img_SVM with scaled data performance: \n",
    "Accuracy: 0.8891203703703704\n",
    "Training Error: 0.9770833333333333\n",
    "Testing Error: 0.8891203703703704\n",
    "Validation Error: 0.9172916666666666\n",
    "\"\"\"\n",
    "\n",
    "# df = pd.read_csv(\"./Datasets/celeba/labels.csv\")\n",
    "# df = split_df(df)\n",
    "# print(df)\n",
    "# img_name_data = df['img_name']\n",
    "# gender_data = df['gender']\n",
    "# smiling_data = df['smiling']\n",
    "\n",
    "# model.fit(X_train, y_train).score(X_train, y_train) FOR TRAINING ERROR\n",
    "#     train_errors.append(enet.score(X_train, y_train))\n",
    "#     test_errors.append(enet.score(X_test, y_test))\n",
    "# classification_report(expected, y_1)\n",
    "\n",
    "# Exhaustive List \n",
    "#     param_grid = [\n",
    "#   {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "#   {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "#  ]\n",
    "\n",
    "# def get_data(X, y):\n",
    "#     Y = np.array([y, -(y - 1)]).T\n",
    "#     tr_X = X[:100]\n",
    "#     tr_Y = Y[:100]\n",
    "#     te_X = X[100:]\n",
    "#     te_Y = Y[100:]\n",
    "#     print(len(tr_X))\n",
    "#     print(len(te_X))\n",
    "    \n",
    "#     tr_X = tr_X.reshape(len(tr_X), 68*2)\n",
    "#     tr_Y = list(zip(*tr_Y))[0]\n",
    "#     te_X = te_X.reshape(len(te_X), 68*2)\n",
    "#     te_Y = list(zip(*te_Y))[0]\n",
    "#     return tr_X, tr_Y, te_X, te_Y\n",
    "# tr_X, tr_Y, te_X, te_Y = get_data(landmark_features_celeba, gender_labels)\n",
    "\n",
    "# def scale_data(training_images, test_images):\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(training_images)\n",
    "#     tr_X = scaler.transform(training_images)\n",
    "#     te_X = scaler.transform(test_images)\n",
    "\n",
    "#     return tr_X, te_X\n",
    "\n",
    "# def scale_data(data):\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(data)\n",
    "#     scaled_data = scaler.transform(data)\n",
    "#     return scaled_data\n",
    "\n",
    "# scaled_all_X = scale_data(all_X)\n",
    "# scaled_tr_X = scale_data(tr_X)\n",
    "# scaled_te_X = scale_data(te_X)\n",
    "# pred_img_SVM_scaled = img_SVM(scaled_all_X, all_Y, scaled_tr_X, tr_Y, scaled_te_X, te_Y)\n",
    "\n",
    "# sklearn functions implementation\n",
    "def img_SVM(training_images, training_labels, test_images, test_labels):\n",
    "    classifier = SVC(kernel = \"linear\")\n",
    "    classifier.fit(training_images, training_labels)\n",
    "    pred = classifier.predict(test_images)\n",
    "    print(\"Accuracy:\", accuracy_score(test_labels, pred))\n",
    "#     print(pred)\n",
    "    return pred\n",
    "\n",
    "def img_MLP(training_images, training_labels, test_images, test_labels): \n",
    "    model = MLPClassifier(solver = 'adam', alpha = 1e-5, hidden_layer_sizes = (3,2), random_state = 1)\n",
    "    tr_X, te_X = scale_data(training_images, test_images)\n",
    "    model.fit(training_images, training_labels)\n",
    "    pred = model.predict(test_images)\n",
    "    print(\"Accuracy:\", accuracy_score(test_labels, pred))\n",
    "    \n",
    "    return pred\n",
    "\n",
    "# pred_img_SVM = img_SVM(tr_X.reshape((100, 68*2)), list(zip(*tr_Y))[0], te_X.reshape((4700, 68*2)), list(zip(*te_Y))[0])\n",
    "# pred_img_MLP = img_MLP(tr_X.reshape((100, 68*2)), list(zip(*tr_Y))[0], te_X.reshape((4700, 68*2)), list(zip(*te_Y))[0])\n",
    "\n",
    "#     print(pd.DataFrame(clf.cv_results_)[['mean_test_score', 'std_test_score', 'params']])\n",
    "#     print(clf.best_score_)\n",
    "#     print(clf.best_params_)\n",
    "#     print(clf.best_estimator_)\n",
    "#     acc_score_cv = cross_val_score(clf, X_all, y_all, scoring = 'accuracy', cv=5)\n",
    "#     print('SVM with GridCV on all data with K=5 fold cross validation - Accuracy Score: %.4f (+/- %.2f)' % (acc_score_cv.mean(), acc_score_cv.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
