{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os, math, import_ipynb, cv2, dlib, warnings, datetime, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from utils import *\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kenyew/Documents/Git/AMLSassignment19_20/AMLS_19-20_Ken_Yew_Piong_SN16004444'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/Users/kenyew/Documents/Git/AMLSassignment19_20/AMLS_19-20_Ken_Yew_Piong_SN16004444/\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# landmark_features_celeba, gender_labels, smiling_labels = extract_features_labels_from_celeba()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A1 - Gender Recognition from celeba Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Task A1\\nmodel_A1 = A1(args...)                 # Build model object.\\nacc_A1_train = model_A1.train(args...) # Train model based on the training set (you should fine-tune your model based on validation set.)\\nacc_A1_test = model_A1.test(args...)   # Test model based on the test set.\\nClean up memory/GPU etc...             # Some code to free memory if necessary.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Task A1\n",
    "model_A1 = A1(args...)                 # Build model object.\n",
    "acc_A1_train = model_A1.train(args...) # Train model based on the training set (you should fine-tune your model based on validation set.)\n",
    "acc_A1_test = model_A1.test(args...)   # Test model based on the test set.\n",
    "Clean up memory/GPU etc...             # Some code to free memory if necessary.\n",
    "\"\"\"\n",
    "# X_train, y_train, X_test, y_test = get_split_data(landmark_features_celeba, gender_labels, 10)\n",
    "# model_A1, acc_A1_train, acc_A1_test = build_model_task_A(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A2 - Smiling Recognition from celeba Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Task A2\\nmodel_A2 = A2(args...)\\nacc_A2_train = model_A2.train(args...)\\nacc_A2_test = model_A2.test(args...)\\nClean up memory/GPU etc...\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Task A2\n",
    "model_A2 = A2(args...)\n",
    "acc_A2_train = model_A2.train(args...)\n",
    "acc_A2_test = model_A2.test(args...)\n",
    "Clean up memory/GPU etc...\n",
    "\"\"\"\n",
    "# X_train, y_train, X_test, y_test = get_split_data(landmark_features_celeba, smiling_labels, 10)\n",
    "# model_A2, acc_A2_train, acc_A2_test = build_model_task_A(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# landmark_features_cartoon_set, eye_color_labels, face_shape_labels = extract_features_labels_from_cartoon_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B1 - Eye Colour Recognition from cartoon Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Task B1\n",
    "model_B1 = B1(args...)\n",
    "acc_B1_train = model_B1.train(args...)\n",
    "acc_B1_test = model_B1.test(args...)\n",
    "Clean up memory/GPU etc...\n",
    "\"\"\"\n",
    "def scale_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data)\n",
    "    scaled_data = scaler.transform(data)\n",
    "    return scaled_data\n",
    "\n",
    "def build_model_task_B(X_train, y_train, X_test, y_test): \n",
    "#     clf = MLPClassifier(solver = 'adam', alpha = 1e-5, hidden_layer_sizes = (3,2), random_state = 1)\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=10000, activation = 'relu', solver='adam', random_state=1, learning_rate = 'adaptive')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc_score_test = accuracy_score(y_test, y_pred)\n",
    "    print('MLP on testing data - Accuracy Score: %.3f (+/- %.3f)' % (acc_score_test.mean(), acc_score_test.std()))\n",
    "    acc_score_train = clf.score(X_train, y_train)\n",
    "    print('MLP on training data - Accuracy Score: %.3f (+/- %.3f)' % (acc_score_train.mean(), acc_score_train.std()))\n",
    "    \n",
    "    return clf, acc_score_train, acc_score_test\n",
    "\n",
    "# X_train, y_train, X_test, y_test = get_split_data(landmark_features_cartoon_set, eye_color_labels, 10)\n",
    "# scaled_X_train = scale_data(X_train)\n",
    "# scaled_X_test = scale_data(X_test)\n",
    "# model_B1, acc_B1_train, acc_B1_test = build_model_task_B(scaled_X_train, y_train, scaled_X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing for Task B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function extracts the landmarks features for all images in the folder 'Dataset/cartoon_set'.\n",
    "It also extracts the eye color and face shape labels for each image.\n",
    ":return:\n",
    "    landmark_features:  an array containing 68 landmark points for each image in which a face was detected\n",
    "    eye_color_labels:   an array containing the eye color labels for each image in\n",
    "                        which a face was detected\n",
    "    face_shape_labels:  an array containing the face shape labels for each image in\n",
    "                        which a face was detected\n",
    "\"\"\"\n",
    "# Global Parameters\n",
    "basedir = './Datasets/cartoon_set'\n",
    "images_dir = os.path.join(basedir,'img')\n",
    "labels_filename = 'labels.csv'\n",
    "\n",
    "# Setting paths of images and labels\n",
    "image_paths = [os.path.join(images_dir, l) for l in os.listdir(images_dir)]\n",
    "target_size = None\n",
    "labels_file = open(os.path.join(basedir, labels_filename), 'r')\n",
    "\n",
    "# Obtaining the labels\n",
    "lines = labels_file.readlines()\n",
    "lines = [line.strip('\"\\n') for line in lines[:]]\n",
    "eye_color_labels = {line.split('\\t')[0] : int(line.split('\\t')[1]) for line in lines[1:]}\n",
    "face_shape_labels = {line.split('\\t')[0] : int(line.split('\\t')[2]) for line in lines[1:]}\n",
    "\n",
    "# Extract landmark features and labels\n",
    "if os.path.isdir(images_dir):\n",
    "    all_features = []\n",
    "    all_eye_color_labels = []\n",
    "    all_face_shape_labels = []\n",
    "    for img_path in image_paths:\n",
    "        if not img_path.endswith('.png'):\n",
    "            continue\n",
    "        file_name= img_path.split('.')[1].split('/')[-1]\n",
    "\n",
    "        # Using the imread function to read each image file. The argument 1 means that the image is NOT grayscaled\n",
    "        img_array = cv2.imread(img_path, cv2.IMREAD_COLOR) \n",
    "\n",
    "        # Downsampling the image from 500 x 500 to 256 x 256 so as to reduce training times and speed up hyperparametrization\n",
    "        resize_img = cv2.resize(img_array, (256, 256))\n",
    "\n",
    "#         plt.imshow(resize_img, cmap = 'jet')\n",
    "#         plt.show()\n",
    "        all_features.append(resize_img)\n",
    "        all_eye_color_labels.append(eye_color_labels[file_name])\n",
    "        all_face_shape_labels.append(face_shape_labels[file_name])\n",
    "\n",
    "    img_features = np.array(all_features)\n",
    "    eye_color_labels = np.array(all_eye_color_labels)\n",
    "    face_shape_labels = np.array(all_face_shape_labels)\n",
    "#     return landmark_features, eye_color_labels, face_shape_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 256, 256, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 4. StandardScaler expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-d9206e3584e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mscaled_img_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_img_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-9fe46328577a>\u001b[0m in \u001b[0;36mscale_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mscale_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mscaled_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscaled_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    661\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[1;32m    662\u001b[0m                         \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m                         force_all_finite='allow-nan')\n\u001b[0m\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m         \u001b[0;31m# Even in the case of `with_mean=False`, we update the mean anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0;32m--> 539\u001b[0;31m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 4. StandardScaler expected <= 2."
     ]
    }
   ],
   "source": [
    "print(img_features.shape)\n",
    "scaled_img_features = scale_data(img_features)\n",
    "print(scaled_img_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "Epoch 1/3\n",
      " 768/9000 [=>............................] - ETA: 9:37 - loss: -6697949.7375 - accuracy: 0.1902"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-82dd41d2c526>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;31m# Compiling the CNN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# passing data in batches of 32 and cross validation split of 10% of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;31m# with pwd containing logs folger, enter in terminal: tensorboard --logsdir logs/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    485\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# X_all = np.array(landmark_features_cartoon_set).reshape(7815, 68, 2, 1)\n",
    "X_all = img_features\n",
    "y_all = eye_color_labels\n",
    "\n",
    "# Initialising TensorBoard\n",
    "NAME = f'CNN-binary-classification-64x2-{datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")}'\n",
    "tensorboard = TensorBoard(log_dir = f'logs/{NAME}')\n",
    "\n",
    "# Creating the CNN model\n",
    "model = Sequential() # Initialising the model as a feedforward sequential model layout\n",
    "\"\"\"\n",
    "1st Layer of CNN\n",
    "\"\"\"\n",
    "# Conv2D(64, (3,3), input_shape = X.shape[1:]) - 0: number of neurons, 1: window size 2: input shape\n",
    "model.add(Conv2D(64, (3,3), input_shape = (256,256,3))) # Adding a convolutional layer\n",
    "model.add(Activation('relu')) # Adding a Rectified Linear Unit activation layer\n",
    "model.add(MaxPooling2D(pool_size = (2,2))) # Adding a 2x2 pooling layer\n",
    "\"\"\"\n",
    "2nd Layer of CNN\n",
    "\"\"\"\n",
    "model.add(Conv2D(64, (3,3))) # Adding a convolutional layer\n",
    "model.add(Activation('relu')) # Adding an Rectified Linear Unit activation layer\n",
    "model.add(MaxPooling2D(pool_size = (2,2))) # Adding a 2x2 pooling layer\n",
    "\"\"\"\n",
    "3rd Layer of CNN\n",
    "\"\"\"\n",
    "model.add(Flatten()) # flatten data structure from 2-D to 1-D\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "\"\"\"\n",
    "Output Layer of CNN\n",
    "\"\"\"\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# Compiling the CNN model\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_all, y_all, batch_size = 32, epochs = 3, validation_split = 0.1, callbacks = [tensorboard]) # passing data in batches of 32 and cross validation split of 10% of data\n",
    "# with pwd containing logs folger, enter in terminal: tensorboard --logsdir logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B2 - Face Shape Recognition from cartoon Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP on testing data - Accuracy Score: 0.613 (+/- 0.000)\n",
      "MLP on training data - Accuracy Score: 1.000 (+/- 0.000)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Task B2\n",
    "model_B2 = B2(args...)\n",
    "acc_B2_train = model_B2.train(args...)\n",
    "acc_B2_test = model_B2.test(args...)\n",
    "Clean up memory/GPU etc...\n",
    "\"\"\"\n",
    "X_train, y_train, X_test, y_test = get_split_data(landmark_features_cartoon_set, face_shape_labels, 10)\n",
    "scaled_X_train = scale_data(X_train)\n",
    "scaled_X_test = scale_data(X_test)\n",
    "model_B2, acc_B2_train, acc_B2_test = build_model_task_B(scaled_X_train, y_train, scaled_X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out your results with following format:\n",
    "# print('TA1:{},{};TA2:{},{};TB1:{},{};TB2:{},{};'.format(acc_A1_train, acc_A1_test,\n",
    "#                                                         acc_A2_train, acc_A2_test,\n",
    "#                                                         acc_B1_train, acc_B1_test,\n",
    "#                                                         acc_B2_train, acc_B2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "img_SVM performance: \n",
    "Accuracy: 0.8780092592592592\n",
    "Training Error: 1.0\n",
    "Testing Error: 0.8780092592592592\n",
    "Validation Error: 0.9166666666666664\n",
    "\n",
    "img_SVM_GridCV performance:\n",
    "{'C': 0.1, 'kernel': 'linear'}\n",
    "Accuracy: 0.8900462962962963\n",
    "Training Error: 0.9729166666666667\n",
    "Testing Error: 0.8900462962962963\n",
    "\n",
    "img_SVM with scaled data performance: \n",
    "Accuracy: 0.8891203703703704\n",
    "Training Error: 0.9770833333333333\n",
    "Testing Error: 0.8891203703703704\n",
    "Validation Error: 0.9172916666666666\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SVM with GridCV on TASK A1\n",
    "Best parameters set found on training dataset:\n",
    "\n",
    "{'C': 0.01, 'kernel': 'linear'}\n",
    "\n",
    "Grid scores on training dataset:\n",
    "\n",
    "0.265 (+/-0.004) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.265 (+/-0.004) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.265 (+/-0.004) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.265 (+/-0.004) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.731 (+/-0.178) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.366 (+/-0.406) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.826 (+/-0.073) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.824 (+/-0.092) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.845 (+/-0.102) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.829 (+/-0.090) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.861 (+/-0.071) for {'C': 5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.877 (+/-0.107) for {'C': 5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.855 (+/-0.060) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.878 (+/-0.101) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.909 (+/-0.073) for {'C': 0.01, 'kernel': 'linear'}\n",
    "0.894 (+/-0.056) for {'C': 0.05, 'kernel': 'linear'}\n",
    "0.900 (+/-0.050) for {'C': 0.1, 'kernel': 'linear'}\n",
    "0.885 (+/-0.092) for {'C': 0.5, 'kernel': 'linear'}\n",
    "0.879 (+/-0.091) for {'C': 1, 'kernel': 'linear'}\n",
    "0.879 (+/-0.091) for {'C': 5, 'kernel': 'linear'}\n",
    "0.879 (+/-0.091) for {'C': 10, 'kernel': 'linear'}\n",
    "0.893 (+/-0.097) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.904 (+/-0.083) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.893 (+/-0.097) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.896 (+/-0.098) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.893 (+/-0.097) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.894 (+/-0.096) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.893 (+/-0.097) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.894 (+/-0.096) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.893 (+/-0.097) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.894 (+/-0.096) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.893 (+/-0.097) for {'C': 5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.894 (+/-0.096) for {'C': 5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.893 (+/-0.097) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.894 (+/-0.096) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "\n",
    "Detailed classification report:\n",
    "\n",
    "The model is trained on the full training dataset.\n",
    "The scores are computed on the full testing dataset.\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.89      0.91      0.90      2176\n",
    "         1.0       0.91      0.88      0.90      2144\n",
    "\n",
    "    accuracy                           0.90      4320\n",
    "   macro avg       0.90      0.90      0.90      4320\n",
    "weighted avg       0.90      0.90      0.90      4320\n",
    "\n",
    "\n",
    "Best estimator found: SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)\n",
    "Best parameters set found: {'C': 0.01, 'kernel': 'linear'}\n",
    "SVM with GridCV on testing data - Accuracy Score: 0.898 (+/- 0.000)\n",
    "SVM with GridCV on training data - Accuracy Score: 0.936 (+/- 0.000)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SVM with GridCV on TASK A2\n",
    "# Tuning hyper-parameters for precision\n",
    "\n",
    "Best parameters set found on training dataset:\n",
    "\n",
    "{'C': 5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "\n",
    "Grid scores on training dataset:\n",
    "\n",
    "0.264 (+/-0.005) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.264 (+/-0.005) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.840 (+/-0.093) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.837 (+/-0.123) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.863 (+/-0.055) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.866 (+/-0.088) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.860 (+/-0.062) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.873 (+/-0.076) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.868 (+/-0.066) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.871 (+/-0.060) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.861 (+/-0.095) for {'C': 5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.881 (+/-0.055) for {'C': 5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.850 (+/-0.083) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.881 (+/-0.073) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.878 (+/-0.079) for {'C': 0.01, 'kernel': 'linear'}\n",
    "0.855 (+/-0.081) for {'C': 0.05, 'kernel': 'linear'}\n",
    "0.850 (+/-0.095) for {'C': 0.1, 'kernel': 'linear'}\n",
    "0.842 (+/-0.101) for {'C': 0.5, 'kernel': 'linear'}\n",
    "0.846 (+/-0.119) for {'C': 1, 'kernel': 'linear'}\n",
    "0.833 (+/-0.132) for {'C': 5, 'kernel': 'linear'}\n",
    "0.833 (+/-0.132) for {'C': 10, 'kernel': 'linear'}\n",
    "0.859 (+/-0.085) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.860 (+/-0.074) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.859 (+/-0.085) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.855 (+/-0.101) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.859 (+/-0.085) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.860 (+/-0.085) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.859 (+/-0.085) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.860 (+/-0.085) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.859 (+/-0.085) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.860 (+/-0.085) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.859 (+/-0.085) for {'C': 5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.860 (+/-0.085) for {'C': 5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.859 (+/-0.085) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.860 (+/-0.085) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "\n",
    "Detailed classification report:\n",
    "\n",
    "The model is trained on the full training dataset.\n",
    "The scores are computed on the full testing dataset.\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.86      0.91      0.88      2117\n",
    "         1.0       0.91      0.86      0.88      2203\n",
    "\n",
    "    accuracy                           0.88      4320\n",
    "   macro avg       0.88      0.88      0.88      4320\n",
    "weighted avg       0.88      0.88      0.88      4320\n",
    "\n",
    "\n",
    "Best estimator found: SVC(C=5, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "Best parameters set found: {'C': 5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "SVM with GridCV on testing data - Accuracy Score: 0.881 (+/- 0.000)\n",
    "SVM with GridCV on training data - Accuracy Score: 0.914 (+/- 0.000)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SVM with GridCV on TASK B1\n",
    "# Tuning hyper-parameters for precision\n",
    "\n",
    "Best parameters set found on training dataset:\n",
    "\n",
    "{'C': 0.01, 'kernel': 'linear'}\n",
    "\n",
    "Grid scores on training dataset:\n",
    "\n",
    "0.044 (+/-0.002) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.044 (+/-0.002) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.044 (+/-0.002) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.145 (+/-0.141) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.140 (+/-0.170) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.113 (+/-0.038) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.303 (+/-0.126) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.258 (+/-0.100) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.287 (+/-0.104) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.286 (+/-0.128) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.281 (+/-0.078) for {'C': 5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.318 (+/-0.107) for {'C': 5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.284 (+/-0.098) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.327 (+/-0.102) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.346 (+/-0.043) for {'C': 0.01, 'kernel': 'linear'}\n",
    "0.341 (+/-0.105) for {'C': 0.05, 'kernel': 'linear'}\n",
    "0.340 (+/-0.112) for {'C': 0.1, 'kernel': 'linear'}\n",
    "0.320 (+/-0.114) for {'C': 0.5, 'kernel': 'linear'}\n",
    "0.306 (+/-0.090) for {'C': 1, 'kernel': 'linear'}\n",
    "0.301 (+/-0.102) for {'C': 5, 'kernel': 'linear'}\n",
    "0.306 (+/-0.086) for {'C': 10, 'kernel': 'linear'}\n",
    "0.307 (+/-0.124) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.312 (+/-0.096) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.309 (+/-0.129) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.302 (+/-0.045) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.308 (+/-0.132) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.306 (+/-0.078) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.308 (+/-0.132) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.300 (+/-0.059) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.308 (+/-0.132) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.301 (+/-0.057) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.308 (+/-0.132) for {'C': 5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.300 (+/-0.058) for {'C': 5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.308 (+/-0.132) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.299 (+/-0.056) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "\n",
    "Detailed classification report:\n",
    "\n",
    "The model is trained on the full training dataset.\n",
    "The scores are computed on the full testing dataset.\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.30      0.32      0.31      1408\n",
    "           1       0.25      0.24      0.24      1381\n",
    "           2       0.21      0.14      0.17      1412\n",
    "           3       0.36      0.41      0.38      1395\n",
    "           4       0.52      0.58      0.55      1438\n",
    "\n",
    "    accuracy                           0.34      7034\n",
    "   macro avg       0.33      0.34      0.33      7034\n",
    "weighted avg       0.33      0.34      0.33      7034\n",
    "\n",
    "\n",
    "Best estimator found: SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)\n",
    "Best parameters set found: {'C': 0.01, 'kernel': 'linear'}\n",
    "SVM with GridCV on testing data - Accuracy Score: 0.339 (+/- 0.000)\n",
    "SVM with GridCV on training data - Accuracy Score: 0.559 (+/- 0.000)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SVM with GridCV on TASK B2\n",
    "# Tuning hyper-parameters for precision\n",
    "\n",
    "Best parameters set found on training dataset:\n",
    "\n",
    "{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "\n",
    "Grid scores on training dataset:\n",
    "\n",
    "0.048 (+/-0.001) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.048 (+/-0.001) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.048 (+/-0.001) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.048 (+/-0.001) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.139 (+/-0.166) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.147 (+/-0.070) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.579 (+/-0.191) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.470 (+/-0.212) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.613 (+/-0.080) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.550 (+/-0.129) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.602 (+/-0.104) for {'C': 5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.679 (+/-0.101) for {'C': 5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.606 (+/-0.107) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.688 (+/-0.061) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.674 (+/-0.136) for {'C': 0.01, 'kernel': 'linear'}\n",
    "0.646 (+/-0.123) for {'C': 0.05, 'kernel': 'linear'}\n",
    "0.647 (+/-0.125) for {'C': 0.1, 'kernel': 'linear'}\n",
    "0.598 (+/-0.129) for {'C': 0.5, 'kernel': 'linear'}\n",
    "0.582 (+/-0.126) for {'C': 1, 'kernel': 'linear'}\n",
    "0.554 (+/-0.122) for {'C': 5, 'kernel': 'linear'}\n",
    "0.551 (+/-0.126) for {'C': 10, 'kernel': 'linear'}\n",
    "0.589 (+/-0.120) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.593 (+/-0.110) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.589 (+/-0.120) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.591 (+/-0.111) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.589 (+/-0.120) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.591 (+/-0.111) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.589 (+/-0.120) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.591 (+/-0.111) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.589 (+/-0.120) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.591 (+/-0.111) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.589 (+/-0.120) for {'C': 5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.591 (+/-0.111) for {'C': 5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.589 (+/-0.120) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.591 (+/-0.111) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "\n",
    "Detailed classification report:\n",
    "\n",
    "The model is trained on the full training dataset.\n",
    "The scores are computed on the full testing dataset.\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.68      0.61      0.65      1389\n",
    "           1       0.53      0.65      0.59      1317\n",
    "           2       0.71      0.74      0.72      1497\n",
    "           3       0.67      0.62      0.64      1411\n",
    "           4       0.84      0.77      0.81      1420\n",
    "\n",
    "    accuracy                           0.68      7034\n",
    "   macro avg       0.69      0.68      0.68      7034\n",
    "weighted avg       0.69      0.68      0.68      7034\n",
    "\n",
    "\n",
    "Best estimator found: SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "Best parameters set found: {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "SVM with GridCV on testing data - Accuracy Score: 0.680 (+/- 0.000)\n",
    "SVM with GridCV on training data - Accuracy Score: 0.903 (+/- 0.000)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"./Datasets/celeba/labels.csv\")\n",
    "# df = split_df(df)\n",
    "# print(df)\n",
    "# img_name_data = df['img_name']\n",
    "# gender_data = df['gender']\n",
    "# smiling_data = df['smiling']\n",
    "\n",
    "# model.fit(X_train, y_train).score(X_train, y_train) FOR TRAINING ERROR\n",
    "#     train_errors.append(enet.score(X_train, y_train))\n",
    "#     test_errors.append(enet.score(X_test, y_test))\n",
    "# classification_report(expected, y_1)\n",
    "\n",
    "# Exhaustive List \n",
    "#     param_grid = [\n",
    "#   {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "#   {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "#  ]\n",
    "\n",
    "# def get_data(X, y):\n",
    "#     Y = np.array([y, -(y - 1)]).T\n",
    "#     tr_X = X[:100]\n",
    "#     tr_Y = Y[:100]\n",
    "#     te_X = X[100:]\n",
    "#     te_Y = Y[100:]\n",
    "#     print(len(tr_X))\n",
    "#     print(len(te_X))\n",
    "    \n",
    "#     tr_X = tr_X.reshape(len(tr_X), 68*2)\n",
    "#     tr_Y = list(zip(*tr_Y))[0]\n",
    "#     te_X = te_X.reshape(len(te_X), 68*2)\n",
    "#     te_Y = list(zip(*te_Y))[0]\n",
    "#     return tr_X, tr_Y, te_X, te_Y\n",
    "# tr_X, tr_Y, te_X, te_Y = get_data(landmark_features_celeba, gender_labels)\n",
    "\n",
    "# def scale_data(training_images, test_images):\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(training_images)\n",
    "#     tr_X = scaler.transform(training_images)\n",
    "#     te_X = scaler.transform(test_images)\n",
    "\n",
    "#     return tr_X, te_X\n",
    "\n",
    "# sklearn functions implementation\n",
    "def img_SVM(training_images, training_labels, test_images, test_labels):\n",
    "    classifier = SVC(kernel = \"linear\")\n",
    "    classifier.fit(training_images, training_labels)\n",
    "    pred = classifier.predict(test_images)\n",
    "    print(\"Accuracy:\", accuracy_score(test_labels, pred))\n",
    "#     print(pred)\n",
    "    return pred\n",
    "\n",
    "\n",
    "# pred_img_SVM = img_SVM(tr_X.reshape((100, 68*2)), list(zip(*tr_Y))[0], te_X.reshape((4700, 68*2)), list(zip(*te_Y))[0])\n",
    "# pred_img_MLP = img_MLP(tr_X.reshape((100, 68*2)), list(zip(*tr_Y))[0], te_X.reshape((4700, 68*2)), list(zip(*te_Y))[0])\n",
    "\n",
    "#     print(pd.DataFrame(clf.cv_results_)[['mean_test_score', 'std_test_score', 'params']])\n",
    "#     print(clf.best_score_)\n",
    "#     print(clf.best_params_)\n",
    "#     print(clf.best_estimator_)\n",
    "\n",
    "# CROSS VALIDATION\n",
    "# X_all = landmark_features_celeba.reshape(len(landmark_features_celeba), 68*2)\n",
    "# Y = np.array([gender_labels, -(gender_labels - 1)]).T\n",
    "# y_all = list(zip(*Y))[0]\n",
    "#     acc_score_cv = cross_val_score(clf, X_all, y_all, scoring = 'accuracy', cv=5)\n",
    "#     print('SVM with GridCV on all data with K=5 fold cross validation - Accuracy Score: %.4f (+/- %.2f)' % (acc_score_cv.mean(), acc_score_cv.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
