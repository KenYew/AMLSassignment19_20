{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing Jupyter notebook from utils.ipynb\n"
     ]
    }
   ],
   "source": [
    "import os, math, import_ipynb, cv2, dlib, warnings, datetime, random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, train_test_split\n",
    "\n",
    "from tensorflow.keras.utils import normalize, to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "from utils import *\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/kenyew/Documents/Git/AMLSassignment19_20/AMLS_19-20_Ken_Yew_Piong_SN16004444'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(\"/Users/kenyew/Documents/Git/AMLSassignment19_20/AMLS_19-20_Ken_Yew_Piong_SN16004444/\")\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# landmark_features_celeba, gender_labels, smiling_labels = extract_features_labels_from_celeba()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A1 - Gender Recognition from celeba Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Task A1\n",
    "model_A1 = A1(args...)                 # Build model object.\n",
    "acc_A1_train = model_A1.train(args...) # Train model based on the training set (you should fine-tune your model based on validation set.)\n",
    "acc_A1_test = model_A1.test(args...)   # Test model based on the test set.\n",
    "Clean up memory/GPU etc...             # Some code to free memory if necessary.\n",
    "\"\"\"\n",
    "# X_train, y_train, X_test, y_test = get_split_data(landmark_features_celeba, gender_labels, 10)\n",
    "# model_A1, acc_A1_train, acc_A1_test = build_model_task_A(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task A2 - Smiling Recognition from celeba Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Task A2\n",
    "model_A2 = A2(args...)\n",
    "acc_A2_train = model_A2.train(args...)\n",
    "acc_A2_test = model_A2.test(args...)\n",
    "Clean up memory/GPU etc...\n",
    "\"\"\"\n",
    "# X_train, y_train, X_test, y_test = get_split_data(landmark_features_celeba, smiling_labels, 10)\n",
    "# model_A2, acc_A2_train, acc_A2_test = build_model_task_A(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# landmark_features_cartoon_set, eye_color_labels, face_shape_labels = extract_features_labels_from_cartoon_set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B1 - Eye Colour Recognition from cartoon Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Task B1\n",
    "model_B1 = B1(args...)\n",
    "acc_B1_train = model_B1.train(args...)\n",
    "acc_B1_test = model_B1.test(args...)\n",
    "Clean up memory/GPU etc...\n",
    "\"\"\"\n",
    "def scale_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data)\n",
    "    scaled_data = scaler.transform(data)\n",
    "    return scaled_data\n",
    "\n",
    "# def build_model_task_B1(X_train, y_train, X_test, y_test): \n",
    "# #     clf = MLPClassifier(solver = 'adam', alpha = 1e-5, hidden_layer_sizes = (3,2), random_state = 1)\n",
    "#     clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=10000, activation = 'relu', solver='adam', random_state=1, learning_rate = 'adaptive')\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     y_pred = clf.predict(X_test)\n",
    "#     acc_score_test = accuracy_score(y_test, y_pred)\n",
    "#     print('MLP on testing data - Accuracy Score: %.3f (+/- %.3f)' % (acc_score_test.mean(), acc_score_test.std()))\n",
    "#     acc_score_train = clf.score(X_train, y_train)\n",
    "#     print('MLP on training data - Accuracy Score: %.3f (+/- %.3f)' % (acc_score_train.mean(), acc_score_train.std()))\n",
    "    \n",
    "#     return clf, acc_score_train, acc_score_test\n",
    "\n",
    "# X_train, y_train, X_test, y_test = get_split_data(landmark_features_cartoon_set, eye_color_labels, 10)\n",
    "# scaled_X_train = scale_data(X_train)\n",
    "# scaled_X_test = scale_data(X_test)\n",
    "# model_B1, acc_B1_train, acc_B1_test = build_model_task_B(scaled_X_train, y_train, scaled_X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing for Task B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_task_B(X_train, X_test, y_train, y_test):\n",
    "    # Set the parameters by cross-validation\n",
    "    tuned_parameters = {\n",
    "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
    "    'activation': ['tanh', 'relu'],\n",
    "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive'],\n",
    "}\n",
    "    scores = ['precision'] # 'recall'\n",
    "\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "\n",
    "        clf = GridSearchCV(\n",
    "            MLPClassifier(), tuned_parameters, cv = 3, scoring='%s_macro' % score\n",
    "        )\n",
    "        clf.fit(X_train, y_train)\n",
    "    \n",
    "        print(\"Best parameters set found on training dataset:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on training dataset:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full training dataset.\")\n",
    "        print(\"The scores are computed on the full testing dataset.\")\n",
    "        print()\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()\n",
    "    \n",
    "    print('Best estimator found:', clf.best_estimator_)\n",
    "    print('Best parameters set found:', clf.best_params_)\n",
    "    acc_score_test = accuracy_score(y_test, y_pred)\n",
    "    print('SVM with GridCV on testing data - Accuracy Score: %.3f (+/- %.3f)' % (acc_score_test.mean(), acc_score_test.std()))\n",
    "    acc_score_train = clf.score(X_train, y_train)\n",
    "    print('SVM with GridCV on training data - Accuracy Score: %.3f (+/- %.3f)' % (acc_score_train.mean(), acc_score_train.std()))\n",
    "    \n",
    "    return clf, acc_score_train, acc_score_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_type = 'rgb'\n",
    "\n",
    "# Global Parameters\n",
    "basedir = './Datasets/cartoon_set'\n",
    "images_dir = os.path.join(basedir,'img')\n",
    "labels_filename = 'labels.csv'\n",
    "\n",
    "# Setting paths of images and labels\n",
    "image_paths = [os.path.join(images_dir, l) for l in os.listdir(images_dir)]\n",
    "target_size = None\n",
    "labels_file = open(os.path.join(basedir, labels_filename), 'r')\n",
    "\n",
    "# Obtaining the labels\n",
    "lines = labels_file.readlines()\n",
    "lines = [line.strip('\"\\n') for line in lines[:]]\n",
    "eye_color_labels = {line.split('\\t')[0] : int(line.split('\\t')[1]) for line in lines[1:]}\n",
    "face_shape_labels = {line.split('\\t')[0] : int(line.split('\\t')[2]) for line in lines[1:]}\n",
    "\n",
    "# Extract landmark features and labels\n",
    "if os.path.isdir(images_dir):\n",
    "    all_features = []\n",
    "    all_eye_color_labels = []\n",
    "    all_face_shape_labels = []\n",
    "    for img_path in image_paths[0:500]:\n",
    "        if not img_path.endswith('.png'):\n",
    "            continue\n",
    "        file_name= img_path.split('.')[1].split('/')[-1]\n",
    "\n",
    "        if feature_type == 'rgb':\n",
    "            # Using the imread function to read each image file. The argument 1 means that the image is NOT grayscaled\n",
    "            img_array = cv2.imread(img_path, cv2.IMREAD_COLOR) \n",
    "            # Downsampling the image from 500 x 500 to 256 x 256 so as to reduce training times and speed up hyperparametrization\n",
    "            features = cv2.resize(img_array, (128, 128))\n",
    "#             plt.imshow(img_array, cmap = 'gray')\n",
    "#             plt.show()\n",
    "        elif feature_type == 'landmarks':\n",
    "            # load image\n",
    "            img = image.img_to_array(\n",
    "                image.load_img(img_path,\n",
    "                               target_size=target_size,\n",
    "                               interpolation='bicubic'))\n",
    "            features, _ = run_dlib_shape(img)\n",
    "\n",
    "        if features is not None:\n",
    "            all_features.append(features)\n",
    "            all_eye_color_labels.append(eye_color_labels[file_name])\n",
    "            all_face_shape_labels.append(face_shape_labels[file_name])\n",
    "\n",
    "img_features = np.array(all_features)\n",
    "eye_color_labels = np.array(all_eye_color_labels)\n",
    "face_shape_labels = np.array(all_face_shape_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 128, 128, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_type = 'rgb'\n",
    "split_percentage = 80\n",
    "X = img_features\n",
    "y = eye_color_labels\n",
    "Y = np.array([y, -(y - 1)]).T\n",
    "split = int(len(X) * (split_percentage/100))\n",
    "X_train = X[:split]\n",
    "y_train = Y[:split]\n",
    "X_test = X[split:]\n",
    "y_test = Y[split:]\n",
    "\n",
    "if feature_type == 'rgb': \n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "elif feature_type == 'landmarks':\n",
    "    X_train = X_train.reshape(len(X_train), 68*2)\n",
    "    X_test = X_test.reshape(len(X_test), 68*2)\n",
    "\n",
    "y_train = list(zip(*y_train))[0]\n",
    "y_test = list(zip(*y_test))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for precision\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-a6048efff0d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# X_train, X_test, y_train, y_test = get_split_data(img_features, eye_color_labels, 10, 'rgb')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mmodel_B1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_B1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_B1_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model_task_A\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Git/AMLSassignment19_20/AMLS_19-20_Ken_Yew_Piong_SN16004444/utils.ipynb\u001b[0m in \u001b[0;36mbuild_model_task_A\u001b[0;34m(X_train, X_test, y_train, y_test)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    266\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# img_features, eye_color_labels, face_shape_labels = extract_features_labels_from_cartoon_set('rgb')\n",
    "def build_model_task_B1(X_train, X_test, y_train, y_test): \n",
    "#     clf = MLPClassifier(solver = 'adam', alpha = 1e-5, hidden_layer_sizes = (3,2), random_state = 1)\n",
    "    clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=100, activation = 'relu', solver='adam', random_state=1, learning_rate = 'adaptive')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc_score_test = accuracy_score(y_test, y_pred)\n",
    "    print('MLP on testing data - Accuracy Score: %.3f (+/- %.3f)' % (acc_score_test.mean(), acc_score_test.std()))\n",
    "    acc_score_train = clf.score(X_train, y_train)\n",
    "    print('MLP on training data - Accuracy Score: %.3f (+/- %.3f)' % (acc_score_train.mean(), acc_score_train.std()))\n",
    "    \n",
    "    return clf, acc_score_train, acc_score_test\n",
    "\n",
    "def img_SVM(X_train, X_test, y_train, y_test):\n",
    "    clf = SVC(kernel = 'linear', gamma = 'auto')\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "#     print('Best parameters set found:', clf.best_params_)\n",
    "    acc_score_test = accuracy_score(y_test, y_pred)\n",
    "    print('SVM on testing data - Accuracy Score: %.3f (+/- %.3f)' % (acc_score_test.mean(), acc_score_test.std()))\n",
    "    acc_score_train = clf.score(X_train, y_train)\n",
    "    print('SVM on training data - Accuracy Score: %.3f (+/- %.3f)' % (acc_score_train.mean(), acc_score_train.std()))\n",
    "#     acc_score_cv = cross_val_score(clf, X_all, y_all, scoring = 'accuracy', cv=5)\n",
    "#     print('SVM on all data with K=5 fold cross validation - Accuracy Score: %.4f (+/- %.2f)' % (acc_score_cv.mean(), acc_score_cv.std()))\n",
    "    \n",
    "    return clf, acc_score_train, acc_score_test\n",
    "\n",
    "# X_train, X_test, y_train, y_test = get_split_data(img_features, eye_color_labels, 10, 'rgb')\n",
    "model_B1, acc_B1_train, acc_B1_test = build_model_task_A(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_data = img_features.reshape(-1, 256, 256, 1)\n",
    "# print(X_data.shape)\n",
    "# print(img_features.shape)\n",
    "# X_data = random.shuffle(X_data)\n",
    "# X_data /= 255\n",
    "# print(scaled_img_features.shape)\n",
    "\n",
    "# for idx, i in enumerate(X_data): \n",
    "#     cnt = 0\n",
    "#     if type(X_data[idx]) == None: \n",
    "#         cnt += 1\n",
    "# print(cnt)\n",
    "\n",
    "# X_data = random.shuffle(img_features)\n",
    "# X_data /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img_features.shape)\n",
    "print(eye_color_labels.shape)\n",
    "# print(img_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 128, 128, 3)\n",
      "(500, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# X_all = np.array(landmark_features_cartoon_set).reshape(7815, 68, 2, 1)\n",
    "def scale_data(data):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(data)\n",
    "    scaled_data = scaler.transform(data)\n",
    "    return scaled_data\n",
    "# X_all = X_all.reshape(X_all.shape[0], 128, 128, 3)\n",
    "# # X_all = np.array(X_all).reshape(-1, 128, 128, 1)\n",
    "# X_all = scale_data(X_all)\n",
    "\n",
    "X_all = img_features\n",
    "print(X_all.shape)\n",
    "X_all = normalize(X_all, axis=1)\n",
    "print(X_all.shape)\n",
    "y_all = eye_color_labels\n",
    "y_all = to_categorical(eye_color_labels, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 5)\n",
      "[3 3 1 4 0]\n",
      "[[0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0.]]\n",
      "(500, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_all.shape)\n",
    "print(eye_color_labels[0:5])\n",
    "print(y_all[0:5])\n",
    "print(X_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (500, 5) was passed for an output of shape (None, 1) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-038ee0285be4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Compiling the CNN model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_all\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# passing data in batches of 32 and cross validation split of 10% of data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;31m# with pwd containing logs folger, enter in terminal: tensorboard --logsdir logs/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m         steps=steps_per_epoch)\n\u001b[0m\u001b[1;32m    517\u001b[0m     (x, y, sample_weights,\n\u001b[1;32m    518\u001b[0m      \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2536\u001b[0m           \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[0;32m-> 2538\u001b[0;31m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m   2539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2540\u001b[0m       \u001b[0;31m# If sample weight mode has not been set and weights are None for all the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    741\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[1;32m    742\u001b[0m                            \u001b[0;34m' was passed for an output of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m                            \u001b[0;34m' while using as loss `'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m                            \u001b[0;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                            'as the output.')\n",
      "\u001b[0;31mValueError\u001b[0m: A target array with shape (500, 5) was passed for an output of shape (None, 1) while using as loss `categorical_crossentropy`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "# Initialising TensorBoard\n",
    "NAME = f'CNN-binary-classification-64x2-{datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")}'\n",
    "tensorboard = TensorBoard(log_dir = f'logs/{NAME}')\n",
    "\n",
    "# Creating the CNN model\n",
    "model = Sequential() # Initialising the model as a feedforward sequential model layout\n",
    "\"\"\"\n",
    "1st Layer of CNN\n",
    "\"\"\"\n",
    "# Conv2D(64, (3,3), input_shape = X.shape[1:]) - 0: number of neurons, 1: window size 2: input shape\n",
    "model.add(Conv2D(64, (3,3), input_shape = (128,128,3))) # Adding a convolutional layer\n",
    "model.add(Activation('relu')) # Adding a Rectified Linear Unit activation layer\n",
    "model.add(MaxPooling2D(pool_size = (2,2))) # Adding a 2x2 pooling layer\n",
    "\"\"\"\n",
    "2nd Layer of CNN\n",
    "\"\"\"\n",
    "model.add(Conv2D(64, (3,3))) # Adding a convolutional layer\n",
    "model.add(Activation('relu')) # Adding an Rectified Linear Unit activation layer\n",
    "model.add(MaxPooling2D(pool_size = (2,2))) # Adding a 2x2 pooling layer\n",
    "\"\"\"\n",
    "3rd Layer of CNN\n",
    "\"\"\"\n",
    "model.add(Flatten()) # flatten data structure from 2-D to 1-D\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "\"\"\"\n",
    "Output Layer of CNN\n",
    "\"\"\"\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# Compiling the CNN model\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "model.fit(X_all, y_all, batch_size = 32, epochs = 1, validation_split = 0.1, callbacks = [tensorboard]) # passing data in batches of 32 and cross validation split of 10% of data\n",
    "# with pwd containing logs folger, enter in terminal: tensorboard --logsdir logs/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task B2 - Face Shape Recognition from cartoon Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Task B2\n",
    "model_B2 = B2(args...)\n",
    "acc_B2_train = model_B2.train(args...)\n",
    "acc_B2_test = model_B2.test(args...)\n",
    "Clean up memory/GPU etc...\n",
    "\"\"\"\n",
    "X_train, y_train, X_test, y_test = get_split_data(landmark_features_cartoon_set, face_shape_labels, 10)\n",
    "scaled_X_train = scale_data(X_train)\n",
    "scaled_X_test = scale_data(X_test)\n",
    "model_B2, acc_B2_train, acc_B2_test = build_model_task_B(scaled_X_train, y_train, scaled_X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out your results with following format:\n",
    "# print('TA1:{},{};TA2:{},{};TB1:{},{};TB2:{},{};'.format(acc_A1_train, acc_A1_test,\n",
    "#                                                         acc_A2_train, acc_A2_test,\n",
    "#                                                         acc_B1_train, acc_B1_test,\n",
    "#                                                         acc_B2_train, acc_B2_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "img_SVM performance: \n",
    "Accuracy: 0.8780092592592592\n",
    "Training Error: 1.0\n",
    "Testing Error: 0.8780092592592592\n",
    "Validation Error: 0.9166666666666664\n",
    "\n",
    "img_SVM_GridCV performance:\n",
    "{'C': 0.1, 'kernel': 'linear'}\n",
    "Accuracy: 0.8900462962962963\n",
    "Training Error: 0.9729166666666667\n",
    "Testing Error: 0.8900462962962963\n",
    "\n",
    "img_SVM with scaled data performance: \n",
    "Accuracy: 0.8891203703703704\n",
    "Training Error: 0.9770833333333333\n",
    "Testing Error: 0.8891203703703704\n",
    "Validation Error: 0.9172916666666666\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SVM with GridCV on TASK A1\n",
    "Best parameters set found on training dataset:\n",
    "\n",
    "{'C': 0.01, 'kernel': 'linear'}\n",
    "\n",
    "Grid scores on training dataset:\n",
    "\n",
    "0.265 (+/-0.004) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.265 (+/-0.004) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.265 (+/-0.004) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.265 (+/-0.004) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.731 (+/-0.178) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.366 (+/-0.406) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.826 (+/-0.073) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.824 (+/-0.092) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.845 (+/-0.102) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.829 (+/-0.090) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.861 (+/-0.071) for {'C': 5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.877 (+/-0.107) for {'C': 5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.855 (+/-0.060) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.878 (+/-0.101) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.909 (+/-0.073) for {'C': 0.01, 'kernel': 'linear'}\n",
    "0.894 (+/-0.056) for {'C': 0.05, 'kernel': 'linear'}\n",
    "0.900 (+/-0.050) for {'C': 0.1, 'kernel': 'linear'}\n",
    "0.885 (+/-0.092) for {'C': 0.5, 'kernel': 'linear'}\n",
    "0.879 (+/-0.091) for {'C': 1, 'kernel': 'linear'}\n",
    "0.879 (+/-0.091) for {'C': 5, 'kernel': 'linear'}\n",
    "0.879 (+/-0.091) for {'C': 10, 'kernel': 'linear'}\n",
    "0.893 (+/-0.097) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.904 (+/-0.083) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.893 (+/-0.097) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.896 (+/-0.098) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.893 (+/-0.097) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.894 (+/-0.096) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.893 (+/-0.097) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.894 (+/-0.096) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.893 (+/-0.097) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.894 (+/-0.096) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.893 (+/-0.097) for {'C': 5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.894 (+/-0.096) for {'C': 5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.893 (+/-0.097) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.894 (+/-0.096) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "\n",
    "Detailed classification report:\n",
    "\n",
    "The model is trained on the full training dataset.\n",
    "The scores are computed on the full testing dataset.\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.89      0.91      0.90      2176\n",
    "         1.0       0.91      0.88      0.90      2144\n",
    "\n",
    "    accuracy                           0.90      4320\n",
    "   macro avg       0.90      0.90      0.90      4320\n",
    "weighted avg       0.90      0.90      0.90      4320\n",
    "\n",
    "\n",
    "Best estimator found: SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)\n",
    "Best parameters set found: {'C': 0.01, 'kernel': 'linear'}\n",
    "SVM with GridCV on testing data - Accuracy Score: 0.898 (+/- 0.000)\n",
    "SVM with GridCV on training data - Accuracy Score: 0.936 (+/- 0.000)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SVM with GridCV on TASK A2\n",
    "# Tuning hyper-parameters for precision\n",
    "\n",
    "Best parameters set found on training dataset:\n",
    "\n",
    "{'C': 5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "\n",
    "Grid scores on training dataset:\n",
    "\n",
    "0.264 (+/-0.005) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.264 (+/-0.005) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.840 (+/-0.093) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.837 (+/-0.123) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.863 (+/-0.055) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.866 (+/-0.088) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.860 (+/-0.062) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.873 (+/-0.076) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.868 (+/-0.066) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.871 (+/-0.060) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.861 (+/-0.095) for {'C': 5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.881 (+/-0.055) for {'C': 5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.850 (+/-0.083) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.881 (+/-0.073) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.878 (+/-0.079) for {'C': 0.01, 'kernel': 'linear'}\n",
    "0.855 (+/-0.081) for {'C': 0.05, 'kernel': 'linear'}\n",
    "0.850 (+/-0.095) for {'C': 0.1, 'kernel': 'linear'}\n",
    "0.842 (+/-0.101) for {'C': 0.5, 'kernel': 'linear'}\n",
    "0.846 (+/-0.119) for {'C': 1, 'kernel': 'linear'}\n",
    "0.833 (+/-0.132) for {'C': 5, 'kernel': 'linear'}\n",
    "0.833 (+/-0.132) for {'C': 10, 'kernel': 'linear'}\n",
    "0.859 (+/-0.085) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.860 (+/-0.074) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.859 (+/-0.085) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.855 (+/-0.101) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.859 (+/-0.085) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.860 (+/-0.085) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.859 (+/-0.085) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.860 (+/-0.085) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.859 (+/-0.085) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.860 (+/-0.085) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.859 (+/-0.085) for {'C': 5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.860 (+/-0.085) for {'C': 5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.859 (+/-0.085) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.860 (+/-0.085) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "\n",
    "Detailed classification report:\n",
    "\n",
    "The model is trained on the full training dataset.\n",
    "The scores are computed on the full testing dataset.\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0       0.86      0.91      0.88      2117\n",
    "         1.0       0.91      0.86      0.88      2203\n",
    "\n",
    "    accuracy                           0.88      4320\n",
    "   macro avg       0.88      0.88      0.88      4320\n",
    "weighted avg       0.88      0.88      0.88      4320\n",
    "\n",
    "\n",
    "Best estimator found: SVC(C=5, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "Best parameters set found: {'C': 5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "SVM with GridCV on testing data - Accuracy Score: 0.881 (+/- 0.000)\n",
    "SVM with GridCV on training data - Accuracy Score: 0.914 (+/- 0.000)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SVM with GridCV on TASK B1\n",
    "# Tuning hyper-parameters for precision\n",
    "\n",
    "Best parameters set found on training dataset:\n",
    "\n",
    "{'C': 0.01, 'kernel': 'linear'}\n",
    "\n",
    "Grid scores on training dataset:\n",
    "\n",
    "0.044 (+/-0.002) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.044 (+/-0.002) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.044 (+/-0.002) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.145 (+/-0.141) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.140 (+/-0.170) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.113 (+/-0.038) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.303 (+/-0.126) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.258 (+/-0.100) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.287 (+/-0.104) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.286 (+/-0.128) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.281 (+/-0.078) for {'C': 5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.318 (+/-0.107) for {'C': 5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.284 (+/-0.098) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.327 (+/-0.102) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.346 (+/-0.043) for {'C': 0.01, 'kernel': 'linear'}\n",
    "0.341 (+/-0.105) for {'C': 0.05, 'kernel': 'linear'}\n",
    "0.340 (+/-0.112) for {'C': 0.1, 'kernel': 'linear'}\n",
    "0.320 (+/-0.114) for {'C': 0.5, 'kernel': 'linear'}\n",
    "0.306 (+/-0.090) for {'C': 1, 'kernel': 'linear'}\n",
    "0.301 (+/-0.102) for {'C': 5, 'kernel': 'linear'}\n",
    "0.306 (+/-0.086) for {'C': 10, 'kernel': 'linear'}\n",
    "0.307 (+/-0.124) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.312 (+/-0.096) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.309 (+/-0.129) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.302 (+/-0.045) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.308 (+/-0.132) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.306 (+/-0.078) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.308 (+/-0.132) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.300 (+/-0.059) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.308 (+/-0.132) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.301 (+/-0.057) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.308 (+/-0.132) for {'C': 5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.300 (+/-0.058) for {'C': 5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.308 (+/-0.132) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.299 (+/-0.056) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "\n",
    "Detailed classification report:\n",
    "\n",
    "The model is trained on the full training dataset.\n",
    "The scores are computed on the full testing dataset.\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.30      0.32      0.31      1408\n",
    "           1       0.25      0.24      0.24      1381\n",
    "           2       0.21      0.14      0.17      1412\n",
    "           3       0.36      0.41      0.38      1395\n",
    "           4       0.52      0.58      0.55      1438\n",
    "\n",
    "    accuracy                           0.34      7034\n",
    "   macro avg       0.33      0.34      0.33      7034\n",
    "weighted avg       0.33      0.34      0.33      7034\n",
    "\n",
    "\n",
    "Best estimator found: SVC(C=0.01, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
    "    kernel='linear', max_iter=-1, probability=False, random_state=None,\n",
    "    shrinking=True, tol=0.001, verbose=False)\n",
    "Best parameters set found: {'C': 0.01, 'kernel': 'linear'}\n",
    "SVM with GridCV on testing data - Accuracy Score: 0.339 (+/- 0.000)\n",
    "SVM with GridCV on training data - Accuracy Score: 0.559 (+/- 0.000)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "SVM with GridCV on TASK B2\n",
    "# Tuning hyper-parameters for precision\n",
    "\n",
    "Best parameters set found on training dataset:\n",
    "\n",
    "{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "\n",
    "Grid scores on training dataset:\n",
    "\n",
    "0.048 (+/-0.001) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.048 (+/-0.001) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.048 (+/-0.001) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.048 (+/-0.001) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.139 (+/-0.166) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.147 (+/-0.070) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.579 (+/-0.191) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.470 (+/-0.212) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.613 (+/-0.080) for {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.550 (+/-0.129) for {'C': 1, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.602 (+/-0.104) for {'C': 5, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.679 (+/-0.101) for {'C': 5, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.606 (+/-0.107) for {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}\n",
    "0.688 (+/-0.061) for {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "0.674 (+/-0.136) for {'C': 0.01, 'kernel': 'linear'}\n",
    "0.646 (+/-0.123) for {'C': 0.05, 'kernel': 'linear'}\n",
    "0.647 (+/-0.125) for {'C': 0.1, 'kernel': 'linear'}\n",
    "0.598 (+/-0.129) for {'C': 0.5, 'kernel': 'linear'}\n",
    "0.582 (+/-0.126) for {'C': 1, 'kernel': 'linear'}\n",
    "0.554 (+/-0.122) for {'C': 5, 'kernel': 'linear'}\n",
    "0.551 (+/-0.126) for {'C': 10, 'kernel': 'linear'}\n",
    "0.589 (+/-0.120) for {'C': 0.01, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.593 (+/-0.110) for {'C': 0.01, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.589 (+/-0.120) for {'C': 0.05, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.591 (+/-0.111) for {'C': 0.05, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.589 (+/-0.120) for {'C': 0.1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.591 (+/-0.111) for {'C': 0.1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.589 (+/-0.120) for {'C': 0.5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.591 (+/-0.111) for {'C': 0.5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.589 (+/-0.120) for {'C': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.591 (+/-0.111) for {'C': 1, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.589 (+/-0.120) for {'C': 5, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.591 (+/-0.111) for {'C': 5, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "0.589 (+/-0.120) for {'C': 10, 'gamma': 0.001, 'kernel': 'poly'}\n",
    "0.591 (+/-0.111) for {'C': 10, 'gamma': 0.0001, 'kernel': 'poly'}\n",
    "\n",
    "Detailed classification report:\n",
    "\n",
    "The model is trained on the full training dataset.\n",
    "The scores are computed on the full testing dataset.\n",
    "\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.68      0.61      0.65      1389\n",
    "           1       0.53      0.65      0.59      1317\n",
    "           2       0.71      0.74      0.72      1497\n",
    "           3       0.67      0.62      0.64      1411\n",
    "           4       0.84      0.77      0.81      1420\n",
    "\n",
    "    accuracy                           0.68      7034\n",
    "   macro avg       0.69      0.68      0.68      7034\n",
    "weighted avg       0.69      0.68      0.68      7034\n",
    "\n",
    "\n",
    "Best estimator found: SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
    "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
    "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
    "    tol=0.001, verbose=False)\n",
    "Best parameters set found: {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
    "SVM with GridCV on testing data - Accuracy Score: 0.680 (+/- 0.000)\n",
    "SVM with GridCV on training data - Accuracy Score: 0.903 (+/- 0.000)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"./Datasets/celeba/labels.csv\")\n",
    "# df = split_df(df)\n",
    "# print(df)\n",
    "# img_name_data = df['img_name']\n",
    "# gender_data = df['gender']\n",
    "# smiling_data = df['smiling']\n",
    "\n",
    "# model.fit(X_train, y_train).score(X_train, y_train) FOR TRAINING ERROR\n",
    "#     train_errors.append(enet.score(X_train, y_train))\n",
    "#     test_errors.append(enet.score(X_test, y_test))\n",
    "# classification_report(expected, y_1)\n",
    "\n",
    "# Exhaustive List \n",
    "#     param_grid = [\n",
    "#   {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "#   {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "#  ]\n",
    "\n",
    "# def get_data(X, y):\n",
    "#     Y = np.array([y, -(y - 1)]).T\n",
    "#     tr_X = X[:100]\n",
    "#     tr_Y = Y[:100]\n",
    "#     te_X = X[100:]\n",
    "#     te_Y = Y[100:]\n",
    "#     print(len(tr_X))\n",
    "#     print(len(te_X))\n",
    "    \n",
    "#     tr_X = tr_X.reshape(len(tr_X), 68*2)\n",
    "#     tr_Y = list(zip(*tr_Y))[0]\n",
    "#     te_X = te_X.reshape(len(te_X), 68*2)\n",
    "#     te_Y = list(zip(*te_Y))[0]\n",
    "#     return tr_X, tr_Y, te_X, te_Y\n",
    "# tr_X, tr_Y, te_X, te_Y = get_data(landmark_features_celeba, gender_labels)\n",
    "\n",
    "# def scale_data(training_images, test_images):\n",
    "#     scaler = StandardScaler()\n",
    "#     scaler.fit(training_images)\n",
    "#     tr_X = scaler.transform(training_images)\n",
    "#     te_X = scaler.transform(test_images)\n",
    "\n",
    "#     return tr_X, te_X\n",
    "\n",
    "# sklearn functions implementation\n",
    "def img_SVM(training_images, training_labels, test_images, test_labels):\n",
    "    classifier = SVC(kernel = \"linear\")\n",
    "    classifier.fit(training_images, training_labels)\n",
    "    pred = classifier.predict(test_images)\n",
    "    print(\"Accuracy:\", accuracy_score(test_labels, pred))\n",
    "#     print(pred)\n",
    "    return pred\n",
    "\n",
    "\n",
    "# pred_img_SVM = img_SVM(tr_X.reshape((100, 68*2)), list(zip(*tr_Y))[0], te_X.reshape((4700, 68*2)), list(zip(*te_Y))[0])\n",
    "# pred_img_MLP = img_MLP(tr_X.reshape((100, 68*2)), list(zip(*tr_Y))[0], te_X.reshape((4700, 68*2)), list(zip(*te_Y))[0])\n",
    "\n",
    "#     print(pd.DataFrame(clf.cv_results_)[['mean_test_score', 'std_test_score', 'params']])\n",
    "#     print(clf.best_score_)\n",
    "#     print(clf.best_params_)\n",
    "#     print(clf.best_estimator_)\n",
    "\n",
    "# CROSS VALIDATION\n",
    "# X_all = landmark_features_celeba.reshape(len(landmark_features_celeba), 68*2)\n",
    "# Y = np.array([gender_labels, -(gender_labels - 1)]).T\n",
    "# y_all = list(zip(*Y))[0]\n",
    "#     acc_score_cv = cross_val_score(clf, X_all, y_all, scoring = 'accuracy', cv=5)\n",
    "#     print('SVM with GridCV on all data with K=5 fold cross validation - Accuracy Score: %.4f (+/- %.2f)' % (acc_score_cv.mean(), acc_score_cv.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
